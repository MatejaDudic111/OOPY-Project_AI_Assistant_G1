{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd15f883796ced19",
   "metadata": {},
   "source": [
    "# AI Assistant\n",
    "## Group Members:\n",
    " - Krylova Alena\n",
    " - Dudic Mateja\n",
    " - Saavedra Triana Erwin Omar\n",
    " - Maringer Kelvin\n",
    "\n",
    "## Python Version:\n",
    " - 3.13\n",
    "\n",
    "## Contributions:\n",
    " - Krylova Alena:\n",
    "     - ...\n",
    " - Dudic Mateja:\n",
    "     - ...\n",
    " - Saavedra Triana Erwin Omar:\n",
    "     - ...\n",
    " - Maringer Kelvin:\n",
    "     - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16272c01b8c7987e",
   "metadata": {},
   "source": [
    "# FIRST TIME SETUP\n",
    "# ----------------\n",
    "# MAKE SURE THAT THIS CELL RUNS WITHOUT ERRORS BEFORE PROCEEDING\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e896f8188369ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: no action specified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to C:\\Users\\krylo\\.cache\\kagglehub\\datasets\\prince7489\\daily-ai-assistant-usage-behavior-dataset\\1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.21k/5.21k [00:00<00:00, 2.17MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\krylo\\.cache\\kagglehub\\datasets\\prince7489\\daily-ai-assistant-usage-behavior-dataset\\versions\\1\\Daily_AI_Assistant_Usage_Behavior_Dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# All the packages that have to be installed should be listed here\n",
    "%pip install numpy pandas matplotlib seaborn kagglehub ipywidgets --quiet\n",
    "# This will filter out the output from Jupyter Notebooks when committing to git, so that diffs are cleaner\n",
    "! git config filter.strip-notebook-output.clean 'jupyter nbconvert --ClearOutputPreprocessor.enabled=True --to=notebook --stdin --stdout --log-level=ERROR'\n",
    "\n",
    "import kagglehub\n",
    "import platform\n",
    "\n",
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"prince7489/daily-ai-assistant-usage-behavior-dataset\") + (\"/Daily_AI_Assistant_Usage_Behavior_Dataset.csv\" if platform.system() != \"Windows\" else \"\\\\Daily_AI_Assistant_Usage_Behavior_Dataset.csv\")\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74fab031dec6594",
   "metadata": {},
   "source": [
    "# ----------------------\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9776dc96f35539c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the imports should be listed here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28858041b25066",
   "metadata": {},
   "source": [
    "## *Dataset Overview*\n",
    "The Daily AI Assistant Usage Behavior Dataset captures real-world patterns of how users interact with AI assistants throughout their daily activities. It provides insights into when, how, and for what purposes people used AI tools, as well as session-level characteristics and user satisfaction.\n",
    "\n",
    "The dataset is published on the Kaggle platform and is intended for researchers, developers, and data science practitioners interested in user behavior analysis, personalization systems, recommendation engines, and conversational AI. It covers a wide range of AI usage scenarios, including learning, productivity, research, and routine daily tasks.\n",
    "\n",
    "The dataset contains 300 rows and 8 columns.\n",
    "\n",
    "*Features (their meaning and data types):*  \n",
    "1st column: timestamp - date and time when the interaction with an AI tool started, data type - categorical (string)  \n",
    "2nd column: device - type of device which was used to access an AI tool (desktop, mobile, smart speaker), data type - categorical (string)  \n",
    "3rd column: usage_category - for what purpose the user used an AI tool (education, daily tasks, research and etc), data type - categorical (string)  \n",
    "4th column: prompt_length - lenght of the user`s prompt (measured in charakters), data type 0 integer  \n",
    "5th column: session_length_minutes - duration of the session in minutes, data type - float  \n",
    "6th column: satisfaction_rating - user satisfaction score from 1 to 5, data type - integer  \n",
    "7th column: assistant_model - which AI assistant model was used during the session, data type - categorical(string)  \n",
    "8th column: tokens_used - number of tokens used during the session, data type - integer  \n",
    "\n",
    "Most features from the data set are categorical, making the dataset suitable for analyzing patterns and user behavior segmentation. \n",
    "\n",
    "To obtain a statistical summary of the numerical features, the describe() method was used.\n",
    "It provided key statistics such as mean, standard deviation, minimum and maximum values, as well as quartiles. It allows to better understand distributaion of data.   \n",
    "*Some observations from the desccribe() function:*   \n",
    "The average prompt length is 129 characters, it indicates that users often submit detailed prompts.  \n",
    "The average session duration is about 7.7 minutes, indicating that most interactions with the AI assistant are relatively short.  \n",
    "The average satisfaction rating is close to 3 (on a scale from 1 to 5), which shows users` experience in general is neutral (or positiv.)  \n",
    "Token usage varies significantly, showing the differences in query complexity.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202670a5bdcc0674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp         device usage_category  prompt_length  \\\n",
      "0  2025-02-20 03:29:00        Desktop      Education             14   \n",
      "1  2025-01-08 18:28:00         Mobile    Daily Tasks             32   \n",
      "2  2025-01-12 17:56:00  Smart Speaker      Education            236   \n",
      "3  2025-01-04 09:11:00  Smart Speaker   Productivity             98   \n",
      "4  2025-02-14 19:59:00  Smart Speaker       Research            220   \n",
      "\n",
      "   session_length_minutes  satisfaction_rating assistant_model  tokens_used  \n",
      "0                    7.08                    5         GPT-5.1           44  \n",
      "1                   13.07                    2          GPT-4o         1047  \n",
      "2                   10.15                    4          GPT-4o         1379  \n",
      "3                   14.45                    1           GPT-5         1105  \n",
      "4                    4.50                    5         GPT-5.1          107  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   timestamp               300 non-null    object \n",
      " 1   device                  300 non-null    object \n",
      " 2   usage_category          300 non-null    object \n",
      " 3   prompt_length           300 non-null    int64  \n",
      " 4   session_length_minutes  300 non-null    float64\n",
      " 5   satisfaction_rating     300 non-null    int64  \n",
      " 6   assistant_model         300 non-null    object \n",
      " 7   tokens_used             300 non-null    int64  \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 18.9+ KB\n",
      "None\n",
      "       prompt_length  session_length_minutes  satisfaction_rating  tokens_used\n",
      "count     300.000000              300.000000           300.000000   300.000000\n",
      "mean      129.123333                7.747100             2.986667   780.536667\n",
      "std        70.048011                4.325186             1.411784   428.272858\n",
      "min         5.000000                0.200000             1.000000    32.000000\n",
      "25%        67.750000                4.112500             2.000000   393.250000\n",
      "50%       132.500000                7.690000             3.000000   797.500000\n",
      "75%       187.250000               11.572500             4.000000  1143.250000\n",
      "max       250.000000               14.990000             5.000000  1500.000000\n"
     ]
    }
   ],
   "source": [
    "## Code for the dataset overview Here\n",
    "data = pd.read_csv(dataset_path)\n",
    "print(data.head())\n",
    "print(data.info())   # to get information about the dataframe (number of rows, columns, data types)\n",
    "# to get basic statistics about the dataframe (mean, std, min, max, etc.)\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f27a1210a09e32",
   "metadata": {},
   "source": [
    "## *Data Quality Check*\n",
    " - Additional Notes etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b86ae29dce109",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for the data quality check Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41627c5b859e5e66",
   "metadata": {},
   "source": [
    "## *Data-Preprocessing*\n",
    " - Additional Notes etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29179a8821b1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here you can take for the Data Quality Check\n",
    "RAW_data = pd.read_csv(dataset_path)\n",
    "\n",
    "# first we check the number of missing values in each column\n",
    "print(RAW_data.isnull().sum())\n",
    "# after checking we can see that there are no missing values in the dataset\n",
    "\n",
    "# so for the outliers in this dataset , I think the best aproach would be to leave them and just mark them as outliers. In this dataset the outliers might be relevant data from users that have a diferent behavior than the average user, so removing them would mean losing relevant data.\n",
    "\n",
    "# now we will check for outliers using the IQR method\n",
    "\n",
    "y = RAW_data.select_dtypes(include=[np.number])\n",
    "print(y)\n",
    "for column in y:\n",
    "    quartile_min = RAW_data[column].quantile(0.25)\n",
    "    quartile_max = RAW_data[column].quantile(0.75)\n",
    "\n",
    "    IQR = quartile_max - quartile_min\n",
    "\n",
    "    lower_bound = quartile_min - 1.5 * IQR\n",
    "    upper_bound = quartile_max + 1.5 * IQR\n",
    "\n",
    "    outliers_promt_length = RAW_data[(RAW_data[column] < lower_bound) | (RAW_data[column] > upper_bound)].count()\n",
    "    outliers_promt_length = outliers_promt_length.sum()\n",
    "\n",
    "    print(f\"the number of outliers in {column} is the following: \\n{outliers_promt_length}\")\n",
    "\n",
    " # Start of the data preprocessing\n",
    "\n",
    "# after checking we can see that there are no outliers in the dataset, surprinsing but good.\n",
    "# next we will check for duplicates in the dataset\n",
    "x = RAW_data.duplicated().sum()\n",
    "print(f\"the number of duplicates in the dataset is the following: \\n{x}\")\n",
    "# after checking we can see that there are no duplicates in the dataset\n",
    "\n",
    "#\n",
    "\n",
    "# so we continue with creating the required columns\n",
    "\n",
    "\n",
    "# I made an funtion for this part so its easier to read , and taking noticing that the timestamp is an string i decided to slice the string to get the hour part and then convert it to int to compare it\n",
    "def timeOfDay(hour):\n",
    "    if 5 <= hour <= 11:\n",
    "        return \"morning\"\n",
    "    elif 12 <= hour <= 17:\n",
    "        return \"afternoon\"\n",
    "    elif 18 <= hour <= 22:\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"Night\"\n",
    "\n",
    "RAW_data[\"timeOfDay\"] = RAW_data[\"timestamp\"].apply(lambda x:timeOfDay(int(x[11:-6])))\n",
    "RAW_data[\"year\"] = RAW_data[\"timestamp\"].apply(lambda x:int(x[0:4]))\n",
    "\n",
    "# now we are going to convert the columns and timestamp to their proper datatypes\n",
    "\n",
    "RAW_data[\"timestamp\"] = pd.to_datetime(RAW_data[\"timestamp\"])\n",
    "RAW_data[\"device\"] = RAW_data[\"device\"].astype(\"category\")\n",
    "RAW_data[\"assistant_model\"] = RAW_data[\"assistant_model\"].astype(\"category\")\n",
    "RAW_data[\"timeOfDay\"] = RAW_data[\"timeOfDay\"].astype(\"category\")\n",
    "RAW_data[\"usage_category\"] = RAW_data[\"usage_category\"].astype(\"category\")\n",
    "\n",
    "# note that the numericals stay the same, and I decided to leave year as a number\n",
    "\n",
    "RAW_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa4e3e17c9bb6d",
   "metadata": {},
   "source": [
    "## *Data Analysis*\n",
    " - Additional Notes etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15f1454448cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"helos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9288eee8972a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code for data analysis here\n",
    "print(\"helo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPY_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
